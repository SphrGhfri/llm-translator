NLLB_MODEL=nllb-distilled-1.3B
# FACEBOOK NLLB MODEL (Consider RAM usage and pre-trained model size)    https://github.dev/facebookresearch/fairseq/tree/nllb
# nllb-distilled-1.3B Uses around 5.5 Gigabytes of RAM and it's size is 5 Gigabyte which need to download. But it is very accurate in translating idioms.
# nllb-distilled-600M Uses around 2.5 Gigabytes of RAM and it's size is 2.5 Gigabyte which need to download.
# use "nllb-distilled-600M" if you have lower ram and space.
# CHOOSE BETWEEN "nllb-distilled-600M" OR "nllb-distilled-1.3B"